{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# Data handling and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Sklearn - Preprocessing, Model Selection, Metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    average_precision_score, confusion_matrix, precision_recall_curve, fbeta_score\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Imbalanced Learning\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Captum for model interpretability\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Custom Functions\n",
    "sys.path.append('./model')\n",
    "from custom_functions import load_raw_data, extract_icd_codes, extract_dynamic_data_dict, extract_demographic_features, summarize_dynamic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed for all packages\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seeds to make the experiment more reproducible.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files for 5% subset loaded successfully.\n",
      "Number of stays: 2379\n",
      "ICD Features shape: (2379, 1458)\n",
      "Summarized Dynamic Features shape: (2379, 16)\n",
      "Demographic Features shape: (2379, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define the percentage to load\n",
    "percentage = '10%'  # Change this to '5%', '10%', etc., as needed\n",
    "\n",
    "# Base directory for the data subsets\n",
    "base_dir = f'./data/subsets/{percentage}_subsets/'\n",
    "\n",
    "# Load Labels\n",
    "labels = pd.read_csv(f'{base_dir}labels.csv')\n",
    "stay_ids = labels['stay_id'].unique()\n",
    "\n",
    "# Load static features\n",
    "icd_features = pd.read_pickle(f'{base_dir}icd_code_features.pkl')\n",
    "\n",
    "# Load summarized dynamic features\n",
    "sum_dynamic_features = pd.read_pickle(f'{base_dir}sum_dynamic_features.pkl')\n",
    "\n",
    "# Load demographic features\n",
    "demographic_features = pd.read_pickle(f'{base_dir}demographic_features.pkl')\n",
    "\n",
    "# Print information to confirm the files are loaded\n",
    "print(f\"Files for {percentage} subset loaded successfully.\")\n",
    "print(f\"Number of stays: {len(stay_ids)}\")\n",
    "print(f\"ICD Features shape: {icd_features.shape}\")\n",
    "print(f\"Summarized Dynamic Features shape: {sum_dynamic_features.shape}\")\n",
    "print(f\"Demographic Features shape: {demographic_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames along the columns (axis=1)\n",
    "all_static_features = pd.concat([icd_features, demographic_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and temp sets (temp will be split into validation and test)\n",
    "train_stays, temp_stays = train_test_split(labels, test_size=0.3, random_state=42, stratify=labels['label'])\n",
    "\n",
    "# split temp into test and validation sets equally\n",
    "test_stays, val_stays = train_test_split(temp_stays, test_size=0.5, random_state=42, stratify=temp_stays['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling & Encoding of Static Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slices of icd_code features for each set\n",
    "icd_features_train = icd_features.loc[train_stays['stay_id']]\n",
    "icd_features_val = icd_features.loc[val_stays['stay_id']]\n",
    "icd_features_test = icd_features.loc[test_stays['stay_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slices of all_static features for each set\n",
    "static_features_train = all_static_features.loc[train_stays['stay_id']]\n",
    "static_features_val = all_static_features.loc[val_stays['stay_id']]\n",
    "static_features_test = all_static_features.loc[test_stays['stay_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Continious Columns for the Different Sets\n",
    "continous_static_columns_train = static_features_train[[\"Age\"]]\n",
    "continous_static_columns_val = static_features_val[[\"Age\"]]\n",
    "continous_static_columns_test = static_features_test[[\"Age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Standard Scaler on the Train Set and apply it to Train, Validation and Test Set \n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "scaler.fit(continous_static_columns_train)\n",
    "\n",
    "# Scale Training Set in a way that yields a Data Frame again\n",
    "continous_static_columns_train = pd.DataFrame(\n",
    "    scaler.transform(continous_static_columns_train),\n",
    "    index=continous_static_columns_train.index,\n",
    "    columns=continous_static_columns_train.columns\n",
    ")\n",
    "\n",
    "# Scale Training Set in a way that yields a Data Frame again\n",
    "continous_static_columns_val = pd.DataFrame(\n",
    "    scaler.transform(continous_static_columns_val),\n",
    "    index=continous_static_columns_val.index,\n",
    "    columns=continous_static_columns_val.columns\n",
    ")\n",
    "\n",
    "# Scale Training Set in a way that yields a Data Frame again\n",
    "continous_static_columns_test = pd.DataFrame(\n",
    "    scaler.transform(continous_static_columns_test),\n",
    "    index=continous_static_columns_test.index,\n",
    "    columns=continous_static_columns_test.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Categorical Columns for the Different Sets\n",
    "categorical_columns = ['gender', 'ethnicity', 'insurance']  \n",
    "categorical_static_columns_train = static_features_train[categorical_columns]\n",
    "categorical_static_columns_val = static_features_val[categorical_columns]\n",
    "categorical_static_columns_test = static_features_test[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soere\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "encoder.fit(categorical_static_columns_train)\n",
    "\n",
    "# Apply the encoder to the train, validation, and test data\n",
    "categorical_static_columns_train_encoded = pd.DataFrame(\n",
    "    encoder.transform(categorical_static_columns_train),\n",
    "    index=categorical_static_columns_train.index,\n",
    "    columns=encoder.get_feature_names_out(categorical_columns)\n",
    ")\n",
    "\n",
    "categorical_static_columns_val_encoded = pd.DataFrame(\n",
    "    encoder.transform(categorical_static_columns_val),\n",
    "    index=categorical_static_columns_val.index,\n",
    "    columns=encoder.get_feature_names_out(categorical_columns)\n",
    ")\n",
    "\n",
    "categorical_static_columns_test_encoded = pd.DataFrame(\n",
    "    encoder.transform(categorical_static_columns_test),\n",
    "    index=categorical_static_columns_test.index,\n",
    "    columns=encoder.get_feature_names_out(categorical_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Features (ICD Codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Boolean columns for each set (ICD Codes)\n",
    "bool_static_columns_train = static_features_train[icd_features.columns]\n",
    "bool_static_columns_val = static_features_val[icd_features.columns]\n",
    "bool_static_columns_test = static_features_test[icd_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Boolean Columns to Float for Consistent Formatting\n",
    "bool_static_columns_train = bool_static_columns_train.astype(float)\n",
    "bool_static_columns_val = bool_static_columns_val.astype(float)\n",
    "bool_static_columns_test = bool_static_columns_test.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Data Frames Back into one per Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all parts into one DataFrame using pd.concat\n",
    "processed_static_features_train = pd.concat([continous_static_columns_train, categorical_static_columns_train_encoded, bool_static_columns_train], axis=1)\n",
    "processed_static_features_test = pd.concat([continous_static_columns_test, categorical_static_columns_test_encoded, bool_static_columns_test], axis=1)\n",
    "processed_static_features_val = pd.concat([continous_static_columns_val, categorical_static_columns_val_encoded, bool_static_columns_val], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Embedding of ICD Codes Using Med-BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ICD Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a sequence of ICD codes for each stay_id\n",
    "def create_icd_sequence(row):\n",
    "    # Filter the ICD codes that are present (value == 1.0)\n",
    "    present_codes = [code for code in row.index if row[code] == 1.0]\n",
    "    return ' '.join(present_codes)  # Joining codes into a single string\n",
    "\n",
    "# Apply the function to each row and create a new DataFrame\n",
    "train_icd_sequences = bool_static_columns_train.apply(create_icd_sequence, axis=1).reset_index()\n",
    "train_icd_sequences.columns = ['stay_id', 'icd_sequence']\n",
    "\n",
    "# Apply the function to each row and create a new DataFrame\n",
    "val_icd_sequences = bool_static_columns_val.apply(create_icd_sequence, axis=1).reset_index()\n",
    "val_icd_sequences.columns = ['stay_id', 'icd_sequence']\n",
    "\n",
    "# Apply the function to each row and create a new DataFrame\n",
    "test_icd_sequences = bool_static_columns_test.apply(create_icd_sequence, axis=1).reset_index()\n",
    "test_icd_sequences.columns = ['stay_id', 'icd_sequence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample Minority Class aligning With Oversampled Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### The Sequences are oversampled to align with the oversampled labels.\n",
    "# Separate the classes\n",
    "majority = train_stays[train_stays['label'] == 0]\n",
    "minority = train_stays[train_stays['label'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_upsampled = resample(minority,\n",
    "                              replace=True,           # sample with replacement\n",
    "                              n_samples=len(majority), # to match majority class\n",
    "                              random_state=123)       # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "oversampled_train_labels = pd.concat([majority, minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the stay_id in train_icd_sequences is set as the index if not already\n",
    "train_icd_sequences.set_index('stay_id', inplace=True)\n",
    "\n",
    "# Use the loc method to align and replicate rows in train_icd_sequences according to oversampled_train_labels\n",
    "train_icd_sequences = train_icd_sequences.loc[oversampled_train_labels['stay_id']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort both sequences and labels by stay_id\n",
    "train_icd_sequences.sort_values([\"stay_id\"], inplace=True)\n",
    "oversampled_train_labels.sort_values([\"stay_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th: [ 0. 12. 17. 24. 39.]\n",
      "Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th: [ 2. 12. 16. 22. 38.]\n",
      "Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th: [ 1. 11. 15. 22. 37.]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each ICD sequence\n",
    "train_icd_sequences['length'] = train_icd_sequences['icd_sequence'].apply(lambda x: len(x.split()))\n",
    "# Calculate the length of each ICD sequence\n",
    "val_icd_sequences['length'] = val_icd_sequences['icd_sequence'].apply(lambda x: len(x.split()))\n",
    "# Calculate the length of each ICD sequence\n",
    "test_icd_sequences['length'] = test_icd_sequences['icd_sequence'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Calculate percentiles\n",
    "train_percentiles = np.percentile(train_icd_sequences['length'], [0, 25, 50, 75, 100])  # Modify if you need other percentiles\n",
    "val_percentiles = np.percentile(val_icd_sequences['length'], [0, 25, 50, 75, 100])  # Modify if you need other percentiles\n",
    "test_percentiles = np.percentile(test_icd_sequences['length'], [0, 25, 50, 75, 100])  # Modify if you need other percentiles\n",
    "\n",
    "print(\"Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th:\", train_percentiles)\n",
    "print(\"Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th:\", val_percentiles)\n",
    "print(\"Percentiles of Training sequence lengths: 0th, 25th, 50th, 75th, 100th:\", test_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer for MedBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained('Charangan/MedBERT')\n",
    "\n",
    "# Specify a max_length for tokenization to ensure truncation\n",
    "max_length = 38  # This is a common choice for BERT models, adjust based on your specific needs\n",
    "\n",
    "# Tokenize the sequences with explicit padding and truncation\n",
    "tokenized_train_data = tokenizer(train_icd_sequences['icd_sequence'].tolist(),\n",
    "                           padding=\"max_length\",  # ensures all sequences are padded to the same length\n",
    "                           truncation=True,       # enables truncation to max_length\n",
    "                           max_length=max_length, # explicitly set max_length\n",
    "                           return_tensors=\"pt\")   # returns PyTorch tensors\n",
    "\n",
    "tokenized_val_data = tokenizer(val_icd_sequences['icd_sequence'].tolist(),\n",
    "                           padding=\"max_length\",  # ensures all sequences are padded to the same length\n",
    "                           truncation=True,       # enables truncation to max_length\n",
    "                           max_length=max_length, # explicitly set max_length\n",
    "                           return_tensors=\"pt\")   # returns PyTorch tensors\n",
    "\n",
    "tokenized_test_data = tokenizer(test_icd_sequences['icd_sequence'].tolist(),\n",
    "                           padding=\"max_length\",  # ensures all sequences are padded to the same length\n",
    "                           truncation=True,       # enables truncation to max_length\n",
    "                           max_length=max_length, # explicitly set max_length\n",
    "                           return_tensors=\"pt\")   # returns PyTorch tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MedBERT model\n",
    "MedBERTmodel = AutoModel.from_pretrained('Charangan/MedBERT')\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "MedBERTmodel.eval()\n",
    "\n",
    "# Define input ids and attention masks\n",
    "input_train_ids = tokenized_train_data['input_ids']\n",
    "train_attention_mask = tokenized_train_data['attention_mask']\n",
    "\n",
    "input_val_ids = tokenized_val_data['input_ids']\n",
    "val_attention_mask = tokenized_val_data['attention_mask']\n",
    "\n",
    "input_test_ids = tokenized_test_data['input_ids']\n",
    "test_attention_mask = tokenized_test_data['attention_mask']\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 100  # Adjust this based on your available memory\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = (input_train_ids.size(0) + batch_size - 1) // batch_size\n",
    "\n",
    "# List to store all embeddings\n",
    "all_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 31\n",
      "Processed batch 2 of 31\n",
      "Processed batch 3 of 31\n",
      "Processed batch 4 of 31\n",
      "Processed batch 5 of 31\n",
      "Processed batch 6 of 31\n",
      "Processed batch 7 of 31\n",
      "Processed batch 8 of 31\n",
      "Processed batch 9 of 31\n",
      "Processed batch 10 of 31\n",
      "Processed batch 11 of 31\n",
      "Processed batch 12 of 31\n",
      "Processed batch 13 of 31\n",
      "Processed batch 14 of 31\n",
      "Processed batch 15 of 31\n",
      "Processed batch 16 of 31\n",
      "Processed batch 17 of 31\n",
      "Processed batch 18 of 31\n",
      "Processed batch 19 of 31\n",
      "Processed batch 20 of 31\n",
      "Processed batch 21 of 31\n",
      "Processed batch 22 of 31\n",
      "Processed batch 23 of 31\n",
      "Processed batch 24 of 31\n",
      "Processed batch 25 of 31\n",
      "Processed batch 26 of 31\n",
      "Processed batch 27 of 31\n",
      "Processed batch 28 of 31\n",
      "Processed batch 29 of 31\n",
      "Processed batch 30 of 31\n",
      "Processed batch 31 of 31\n",
      "Embedding generation complete.\n"
     ]
    }
   ],
   "source": [
    "## Embedding Generation for Training Set\n",
    "# Process each batch\n",
    "for i in range(num_batches):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = min(batch_start + batch_size, input_train_ids.size(0))\n",
    "    \n",
    "    # Slice the batch data\n",
    "    batch_input_ids = input_train_ids[batch_start:batch_end]\n",
    "    batch_attention_mask = train_attention_mask[batch_start:batch_end]\n",
    "\n",
    "    # Forward pass to get embeddings\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = MedBERTmodel(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        batch_embeddings = batch_outputs.last_hidden_state  # Extract embeddings\n",
    "    \n",
    "    # Store the embeddings\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Processed batch {i+1} of {num_batches}\")\n",
    "\n",
    "# Concatenate all embeddings to form a single tensor\n",
    "train_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# Now 'embeddings' contains the embeddings for the entire dataset\n",
    "print(\"Embedding generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 31\n",
      "Processed batch 2 of 31\n",
      "Processed batch 3 of 31\n",
      "Processed batch 4 of 31\n",
      "Processed batch 5 of 31\n",
      "Processed batch 6 of 31\n",
      "Processed batch 7 of 31\n",
      "Processed batch 8 of 31\n",
      "Processed batch 9 of 31\n",
      "Processed batch 10 of 31\n",
      "Processed batch 11 of 31\n",
      "Processed batch 12 of 31\n",
      "Processed batch 13 of 31\n",
      "Processed batch 14 of 31\n",
      "Processed batch 15 of 31\n",
      "Processed batch 16 of 31\n",
      "Processed batch 17 of 31\n",
      "Processed batch 18 of 31\n",
      "Processed batch 19 of 31\n",
      "Processed batch 20 of 31\n",
      "Processed batch 21 of 31\n",
      "Processed batch 22 of 31\n",
      "Processed batch 23 of 31\n",
      "Processed batch 24 of 31\n",
      "Processed batch 25 of 31\n",
      "Processed batch 26 of 31\n",
      "Processed batch 27 of 31\n",
      "Processed batch 28 of 31\n",
      "Processed batch 29 of 31\n",
      "Processed batch 30 of 31\n",
      "Processed batch 31 of 31\n",
      "Embedding generation complete.\n"
     ]
    }
   ],
   "source": [
    "## Embedding Generation for Validation Set\n",
    "\n",
    "all_embeddings = []  # Initialize the list to store embeddings\n",
    "\n",
    "# Process each batch\n",
    "for i in range(num_batches):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = min(batch_start + batch_size, input_val_ids.size(0))\n",
    "    \n",
    "    # Slice the batch data\n",
    "    batch_input_ids = input_val_ids[batch_start:batch_end]\n",
    "    batch_attention_mask = val_attention_mask[batch_start:batch_end]\n",
    "\n",
    "    # Forward pass to get embeddings\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = MedBERTmodel(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        batch_embeddings = batch_outputs.last_hidden_state  # Extract embeddings\n",
    "    \n",
    "    # Store the embeddings\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Processed batch {i+1} of {num_batches}\")\n",
    "\n",
    "# Concatenate all embeddings to form a single tensor\n",
    "val_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# Now 'embeddings' contains the embeddings for the entire dataset\n",
    "print(\"Embedding generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1 of 31\n",
      "Processed batch 2 of 31\n",
      "Processed batch 3 of 31\n",
      "Processed batch 4 of 31\n",
      "Processed batch 5 of 31\n",
      "Processed batch 6 of 31\n",
      "Processed batch 7 of 31\n",
      "Processed batch 8 of 31\n",
      "Processed batch 9 of 31\n",
      "Processed batch 10 of 31\n",
      "Processed batch 11 of 31\n",
      "Processed batch 12 of 31\n",
      "Processed batch 13 of 31\n",
      "Processed batch 14 of 31\n",
      "Processed batch 15 of 31\n",
      "Processed batch 16 of 31\n",
      "Processed batch 17 of 31\n",
      "Processed batch 18 of 31\n",
      "Processed batch 19 of 31\n",
      "Processed batch 20 of 31\n",
      "Processed batch 21 of 31\n",
      "Processed batch 22 of 31\n",
      "Processed batch 23 of 31\n",
      "Processed batch 24 of 31\n",
      "Processed batch 25 of 31\n",
      "Processed batch 26 of 31\n",
      "Processed batch 27 of 31\n",
      "Processed batch 28 of 31\n",
      "Processed batch 29 of 31\n",
      "Processed batch 30 of 31\n",
      "Processed batch 31 of 31\n",
      "Embedding generation complete.\n"
     ]
    }
   ],
   "source": [
    "## Embedding Generation for Testing Set\n",
    "\n",
    "all_embeddings = []  # Initialize the list to store embeddings\n",
    "\n",
    "# Process each batch\n",
    "for i in range(num_batches):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = min(batch_start + batch_size, input_test_ids.size(0))\n",
    "    \n",
    "    # Slice the batch data\n",
    "    batch_input_ids = input_test_ids[batch_start:batch_end]\n",
    "    batch_attention_mask = test_attention_mask[batch_start:batch_end]\n",
    "\n",
    "    # Forward pass to get embeddings\n",
    "    with torch.no_grad():\n",
    "        batch_outputs = MedBERTmodel(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        batch_embeddings = batch_outputs.last_hidden_state  # Extract embeddings\n",
    "    \n",
    "    # Store the embeddings\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Processed batch {i+1} of {num_batches}\")\n",
    "\n",
    "# Concatenate all embeddings to form a single tensor\n",
    "test_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# Now 'embeddings' contains the embeddings for the entire dataset\n",
    "print(\"Embedding generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Embedding Shape: torch.Size([3054, 38, 768])\n",
      "Validation Embedding Shape: torch.Size([357, 38, 768])\n",
      "Test Embedding Shape: torch.Size([357, 38, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Embedding Shape:\", train_embeddings.shape)\n",
    "print(\"Validation Embedding Shape:\", val_embeddings.shape)\n",
    "print(\"Test Embedding Shape:\", test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Label Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Train Tensor shape: torch.Size([3054])\n",
      "Label Test Tensor shape: torch.Size([357])\n",
      "Label Validation Tensor shape: torch.Size([357])\n"
     ]
    }
   ],
   "source": [
    "# Convert label columns directly to tensors\n",
    "label_tensor_train = torch.tensor(oversampled_train_labels['label'].values, dtype=torch.float32)\n",
    "label_tensor_test = torch.tensor(test_stays['label'].values, dtype=torch.float32)\n",
    "label_tensor_val = torch.tensor(val_stays['label'].values, dtype=torch.float32)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"Label Train Tensor shape:\", label_tensor_train.shape)\n",
    "print(\"Label Test Tensor shape:\", label_tensor_test.shape)\n",
    "print(\"Label Validation Tensor shape:\", label_tensor_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-defined Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to load tensors\n",
    "tensor_save_path = f'./data/tensors/{percentage}_subset'\n",
    "\n",
    "# Load tensors\n",
    "dynamic_train_tensor_oversampled = torch.load(os.path.join(tensor_save_path, 'dynamic_train_tensor_oversampled.pt'))\n",
    "dynamic_test_tensor = torch.load(os.path.join(tensor_save_path, 'dynamic_test_tensor.pt'))\n",
    "dynamic_val_tensor = torch.load(os.path.join(tensor_save_path, 'dynamic_val_tensor.pt'))\n",
    "\n",
    "label_tensor_train_oversampled = torch.load(os.path.join(tensor_save_path, 'label_tensor_train_oversampled.pt'))\n",
    "label_tensor_test = torch.load(os.path.join(tensor_save_path, 'label_test_tensor.pt'))\n",
    "label_tensor_val = torch.load(os.path.join(tensor_save_path, 'label_val_tensor.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Train Tensor shape: torch.Size([3054])\n",
      "Dynamic Train Tensor shape: torch.Size([3054, 12, 834])\n",
      "Train Embedding Shape: torch.Size([3054, 38, 768])\n",
      "Label Test Tensor shape: torch.Size([357])\n",
      "Dynamic Test Tensor shape: torch.Size([357, 12, 835])\n",
      "Test Embedding Shape: torch.Size([357, 38, 768])\n",
      "Label Validation Tensor shape: torch.Size([357])\n",
      "Dynamic Validation Tensor shape: torch.Size([357, 12, 835])\n",
      "Validation Embedding Shape: torch.Size([357, 38, 768])\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to confirm\n",
    "print(\"Label Train Tensor shape:\", label_tensor_train_oversampled.shape)\n",
    "print(\"Dynamic Train Tensor shape:\", dynamic_train_tensor_oversampled.shape)\n",
    "print(\"Train Embedding Shape:\", train_embeddings.shape)\n",
    "\n",
    "print(\"Label Test Tensor shape:\", label_tensor_test.shape)\n",
    "print(\"Dynamic Test Tensor shape:\", dynamic_test_tensor.shape)\n",
    "print(\"Test Embedding Shape:\", test_embeddings.shape)\n",
    "\n",
    "\n",
    "print(\"Label Validation Tensor shape:\", label_tensor_val.shape)\n",
    "print(\"Dynamic Validation Tensor shape:\", dynamic_val_tensor.shape)\n",
    "print(\"Validation Embedding Shape:\", val_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Tensors Are Identical?\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Verify that the redefined oversampled labels in this notebook are identical to the oversampled labels in the saved tensors\n",
    "print(\"Label Tensors Are Identical?\")\n",
    "print(torch.equal(label_tensor_train, label_tensor_train_oversampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Embeddings and Dynamic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6918, Val Loss: 0.6692\n",
      "Epoch [2/100], Loss: 0.6660, Val Loss: 0.6673\n",
      "Epoch [3/100], Loss: 0.6419, Val Loss: 0.6695\n",
      "Epoch [4/100], Loss: 0.6188, Val Loss: 0.6531\n",
      "Epoch [5/100], Loss: 0.5961, Val Loss: 0.6440\n",
      "Epoch [6/100], Loss: 0.5740, Val Loss: 0.6478\n",
      "Epoch [7/100], Loss: 0.5523, Val Loss: 0.6389\n",
      "Epoch [8/100], Loss: 0.5310, Val Loss: 0.6304\n",
      "Epoch [9/100], Loss: 0.5102, Val Loss: 0.6343\n",
      "Epoch [10/100], Loss: 0.4899, Val Loss: 0.6261\n",
      "Epoch [11/100], Loss: 0.4704, Val Loss: 0.6189\n",
      "Epoch [12/100], Loss: 0.4515, Val Loss: 0.6247\n",
      "Epoch [13/100], Loss: 0.4335, Val Loss: 0.6009\n",
      "Epoch [14/100], Loss: 0.4160, Val Loss: 0.6211\n",
      "Epoch [15/100], Loss: 0.3989, Val Loss: 0.5824\n",
      "Epoch [16/100], Loss: 0.3817, Val Loss: 0.5947\n",
      "Epoch [17/100], Loss: 0.3644, Val Loss: 0.5719\n",
      "Epoch [18/100], Loss: 0.3471, Val Loss: 0.5514\n",
      "Epoch [19/100], Loss: 0.3299, Val Loss: 0.5533\n",
      "Epoch [20/100], Loss: 0.3128, Val Loss: 0.5092\n",
      "Epoch [21/100], Loss: 0.2959, Val Loss: 0.5238\n",
      "Epoch [22/100], Loss: 0.2799, Val Loss: 0.4729\n",
      "Epoch [23/100], Loss: 0.2649, Val Loss: 0.4811\n",
      "Epoch [24/100], Loss: 0.2508, Val Loss: 0.4542\n",
      "Epoch [25/100], Loss: 0.2371, Val Loss: 0.4398\n",
      "Epoch [26/100], Loss: 0.2237, Val Loss: 0.4429\n",
      "Epoch [27/100], Loss: 0.2108, Val Loss: 0.4102\n",
      "Epoch [28/100], Loss: 0.1985, Val Loss: 0.4370\n",
      "Epoch [29/100], Loss: 0.1859, Val Loss: 0.3964\n",
      "Epoch [30/100], Loss: 0.1716, Val Loss: 0.4059\n",
      "Epoch [31/100], Loss: 0.1567, Val Loss: 0.4061\n",
      "Epoch [32/100], Loss: 0.1430, Val Loss: 0.3882\n",
      "Epoch [33/100], Loss: 0.1302, Val Loss: 0.4048\n",
      "Epoch [34/100], Loss: 0.1182, Val Loss: 0.4099\n",
      "Epoch [35/100], Loss: 0.1073, Val Loss: 0.3966\n",
      "Epoch [36/100], Loss: 0.0968, Val Loss: 0.4103\n",
      "Epoch [37/100], Loss: 0.0869, Val Loss: 0.4241\n",
      "Epoch [38/100], Loss: 0.0788, Val Loss: 0.4143\n",
      "Epoch [39/100], Loss: 0.0719, Val Loss: 0.4151\n",
      "Epoch [40/100], Loss: 0.0659, Val Loss: 0.4278\n",
      "Epoch [41/100], Loss: 0.0604, Val Loss: 0.4242\n",
      "Epoch [42/100], Loss: 0.0557, Val Loss: 0.4140\n",
      "Epoch [43/100], Loss: 0.0518, Val Loss: 0.4153\n",
      "Epoch [44/100], Loss: 0.0479, Val Loss: 0.4165\n",
      "Epoch [45/100], Loss: 0.0444, Val Loss: 0.4067\n",
      "Epoch [46/100], Loss: 0.0412, Val Loss: 0.4001\n",
      "Epoch [47/100], Loss: 0.0382, Val Loss: 0.4072\n",
      "Epoch [48/100], Loss: 0.0352, Val Loss: 0.4206\n",
      "Epoch [49/100], Loss: 0.0324, Val Loss: 0.4269\n",
      "Epoch [50/100], Loss: 0.0296, Val Loss: 0.4193\n",
      "Epoch [51/100], Loss: 0.0268, Val Loss: 0.4127\n",
      "Epoch [52/100], Loss: 0.0235, Val Loss: 0.4202\n",
      "Epoch [53/100], Loss: 0.0200, Val Loss: 0.4305\n",
      "Epoch [54/100], Loss: 0.0158, Val Loss: 0.4184\n",
      "Epoch [55/100], Loss: 0.0127, Val Loss: 0.3872\n",
      "Epoch [56/100], Loss: 0.0121, Val Loss: 0.3682\n",
      "Epoch [57/100], Loss: 0.0114, Val Loss: 0.3751\n",
      "Epoch [58/100], Loss: 0.0101, Val Loss: 0.4010\n",
      "Epoch [59/100], Loss: 0.0089, Val Loss: 0.4263\n",
      "Epoch [60/100], Loss: 0.0085, Val Loss: 0.4280\n",
      "Epoch [61/100], Loss: 0.0081, Val Loss: 0.4134\n",
      "Epoch [62/100], Loss: 0.0072, Val Loss: 0.3976\n",
      "Epoch [63/100], Loss: 0.0067, Val Loss: 0.3898\n",
      "Epoch [64/100], Loss: 0.0064, Val Loss: 0.3933\n",
      "Epoch [65/100], Loss: 0.0060, Val Loss: 0.4057\n",
      "Epoch [66/100], Loss: 0.0056, Val Loss: 0.4220\n",
      "Epoch [67/100], Loss: 0.0053, Val Loss: 0.4340\n",
      "Epoch [68/100], Loss: 0.0051, Val Loss: 0.4359\n",
      "Epoch [69/100], Loss: 0.0049, Val Loss: 0.4291\n",
      "Epoch [70/100], Loss: 0.0046, Val Loss: 0.4200\n",
      "Epoch [71/100], Loss: 0.0044, Val Loss: 0.4141\n",
      "Epoch [72/100], Loss: 0.0042, Val Loss: 0.4135\n",
      "Epoch [73/100], Loss: 0.0040, Val Loss: 0.4179\n",
      "Epoch [74/100], Loss: 0.0038, Val Loss: 0.4255\n",
      "Epoch [75/100], Loss: 0.0037, Val Loss: 0.4340\n",
      "Epoch [76/100], Loss: 0.0035, Val Loss: 0.4401\n",
      "Epoch [77/100], Loss: 0.0034, Val Loss: 0.4417\n",
      "Epoch [78/100], Loss: 0.0033, Val Loss: 0.4393\n",
      "Epoch [79/100], Loss: 0.0032, Val Loss: 0.4350\n",
      "Epoch [80/100], Loss: 0.0030, Val Loss: 0.4312\n",
      "Epoch [81/100], Loss: 0.0030, Val Loss: 0.4296\n",
      "Epoch [82/100], Loss: 0.0029, Val Loss: 0.4307\n",
      "Epoch [83/100], Loss: 0.0028, Val Loss: 0.4341\n",
      "Epoch [84/100], Loss: 0.0027, Val Loss: 0.4391\n",
      "Epoch [85/100], Loss: 0.0026, Val Loss: 0.4443\n",
      "Epoch [86/100], Loss: 0.0025, Val Loss: 0.4481\n",
      "Epoch [87/100], Loss: 0.0025, Val Loss: 0.4496\n",
      "Epoch [88/100], Loss: 0.0024, Val Loss: 0.4488\n",
      "Epoch [89/100], Loss: 0.0023, Val Loss: 0.4465\n",
      "Epoch [90/100], Loss: 0.0023, Val Loss: 0.4441\n",
      "Epoch [91/100], Loss: 0.0022, Val Loss: 0.4426\n",
      "Epoch [92/100], Loss: 0.0022, Val Loss: 0.4426\n",
      "Epoch [93/100], Loss: 0.0021, Val Loss: 0.4441\n",
      "Epoch [94/100], Loss: 0.0021, Val Loss: 0.4469\n",
      "Epoch [95/100], Loss: 0.0020, Val Loss: 0.4504\n",
      "Epoch [96/100], Loss: 0.0020, Val Loss: 0.4536\n",
      "Epoch [97/100], Loss: 0.0020, Val Loss: 0.4556\n",
      "Epoch [98/100], Loss: 0.0019, Val Loss: 0.4564\n",
      "Epoch [99/100], Loss: 0.0019, Val Loss: 0.4561\n",
      "Epoch [100/100], Loss: 0.0018, Val Loss: 0.4554\n"
     ]
    }
   ],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, num_dynamic_features, embedding_dim, lstm_hidden_dim, fc_hidden_dim, output_dim):\n",
    "        super(HybridModel, self).__init__()\n",
    "        # LSTM for processing dynamic data\n",
    "        self.lstm = nn.LSTM(input_size=num_dynamic_features, hidden_size=lstm_hidden_dim, batch_first=True)\n",
    "        \n",
    "        # Dense layers for processing embeddings with two layers\n",
    "        self.embedding_fc1 = nn.Linear(embedding_dim, fc_hidden_dim)\n",
    "        self.embedding_fc2 = nn.Linear(fc_hidden_dim, fc_hidden_dim)  # Additional layer\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Final dense layer after concatenation\n",
    "        self.final_fc = nn.Linear(lstm_hidden_dim + fc_hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, dynamic_input, embedding_input):\n",
    "        # LSTM pathway\n",
    "        lstm_out, (hidden, _) = self.lstm(dynamic_input)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Take the last hidden state\n",
    "\n",
    "        # Check if averaging is necessary for embeddings\n",
    "        if embedding_input.dim() > 2:\n",
    "            embedding_input = torch.mean(embedding_input, dim=1)\n",
    "\n",
    "        # Embedding pathway\n",
    "        embedding_out = self.relu(self.embedding_fc1(embedding_input))\n",
    "        embedding_out = self.relu(self.embedding_fc2(embedding_out))  # Pass through second dense layer\n",
    "\n",
    "        # Concatenate outputs\n",
    "        combined_out = torch.cat((lstm_out, embedding_out), dim=1)\n",
    "        \n",
    "        # Final output\n",
    "        final_out = self.sigmoid(self.final_fc(combined_out))\n",
    "        return final_out\n",
    "    \n",
    "# Parameters setup\n",
    "num_dynamic_features = 834  # As per your dynamic data\n",
    "embedding_dim = 768         # Dimension of Med-BERT embeddings\n",
    "lstm_hidden_dim = 128       # Hidden dimension for LSTM\n",
    "fc_hidden_dim = 128         # Hidden dimension for the embedding fully connected layer\n",
    "output_dim = 1              # Output dimension (binary classification)\n",
    "\n",
    "# Instantiate the model\n",
    "model = HybridModel(num_dynamic_features, embedding_dim, lstm_hidden_dim, fc_hidden_dim, output_dim)\n",
    "\n",
    "# Setup the criterion and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define your training loop\n",
    "def train_model(model, criterion, optimizer, dynamic_train, embedding_train, labels_train, dynamic_val, embedding_val, labels_val, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(dynamic_train, embedding_train)\n",
    "        loss = criterion(outputs.squeeze(), labels_train)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(dynamic_val, embedding_val)\n",
    "            val_loss = criterion(val_outputs.squeeze(), labels_val)\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Example use (assuming you have tensors for dynamic data and embeddings ready)\n",
    "train_model(model, criterion, optimizer, dynamic_train_tensor_oversampled, train_embeddings, label_tensor_train_oversampled, dynamic_val_tensor, val_embeddings, label_tensor_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.24\n",
      "Hybrid_Med_BERT Model Performance on Test Set:\n",
      "Accuracy: 0.7311\n",
      "Precision: 0.1827\n",
      "Recall: 0.6333\n",
      "F1 Score: 0.2836\n",
      "AUC-ROC: 0.6700\n",
      "AUPRC: 0.21\n",
      "Performance metrics saved to: ./saved_models/Hybrid_Med-BERT/trained_on_5%/Hybrid_Med_BERT_metrics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soere\\AppData\\Local\\Temp\\ipykernel_6028\\1482245464.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta_scores = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_hybrid_med_bert_model(model, dynamic_test, embedding_test, labels_test, directory, model_name, beta=2):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    sns.set()  # For better plot styling\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predictions\n",
    "        outputs = model(dynamic_test, embedding_test).squeeze()\n",
    "        test_probs = outputs.numpy()  # Probability predictions\n",
    "\n",
    "    # True labels for comparison\n",
    "    true_labels = labels_test.numpy()\n",
    "\n",
    "    # Calculate precision-recall curve and corresponding thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(true_labels, test_probs)\n",
    "\n",
    "    # Calculate F-beta scores for each possible threshold\n",
    "    f_beta_scores = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "    f_beta_scores = np.nan_to_num(f_beta_scores)  # Handling NaNs\n",
    "\n",
    "    # Find the threshold that maximizes the F-beta score\n",
    "    optimal_idx = np.argmax(f_beta_scores)\n",
    "    best_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Use the best threshold found\n",
    "    test_predictions = (test_probs > best_threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, test_predictions)\n",
    "    precision = precision_score(true_labels, test_predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, test_predictions)\n",
    "    f1 = f1_score(true_labels, test_predictions)\n",
    "    auc_roc = roc_auc_score(true_labels, test_probs)\n",
    "    auprc = average_precision_score(true_labels, test_probs)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "    print(f\"{model_name} Model Performance on Test Set:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "    print(f\"AUPRC: {auprc:.2f}\")\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, test_predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{directory}/{model_name}_confusion_matrix.png')\n",
    "    plt.close()  # Close the plot to avoid display\n",
    "\n",
    "    # Save performance metrics to a text file\n",
    "    metrics_filepath = f'{directory}/{model_name}_metrics.txt'\n",
    "    with open(metrics_filepath, 'w') as f:\n",
    "        f.write(f\"{model_name} Model Performance on Test Set:\\n\")\n",
    "        f.write(f\"Best Threshold: {best_threshold:.2f}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"AUC-ROC: {auc_roc:.4f}\\n\")\n",
    "        f.write(f\"AUPRC: {auprc:.2f}\\n\")\n",
    "\n",
    "    print(f\"Performance metrics saved to: {metrics_filepath}\")\n",
    "\n",
    "# Example usage\n",
    "evaluate_hybrid_med_bert_model(model, dynamic_test_tensor, test_embeddings, label_tensor_test, f'./saved_models/Hybrid_Med-BERT/trained_on_{percentage}', 'Hybrid_Med_BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and optimizer state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, f'./saved_models/Hybrid_Med-BERT/trained_on_{percentage}/best_Hybrid_Med-BERT_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
