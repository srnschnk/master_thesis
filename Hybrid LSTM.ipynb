{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and manipulation\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine learning and metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, \n",
    "                             average_precision_score, confusion_matrix, precision_recall_curve, \n",
    "                             fbeta_score)\n",
    "\n",
    "# PyTorch components\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Custom Functions\n",
    "sys.path.append('./model')\n",
    "from custom_functions import load_raw_data, extract_icd_codes, extract_dynamic_data_dict, extract_demographic_features, summarize_dynamic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed for all packages\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seeds to make the experiment more reproducible.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid_lstm_model(model, dynamic_test_tensor, static_test_tensor, label_tensor_test, directory, model_name, beta=2):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    sns.set()  # For better plot styling\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Predict on the test set\n",
    "        test_outputs = model(dynamic_test_tensor, static_test_tensor).squeeze()\n",
    "        test_probs = test_outputs.numpy()  # Probability predictions\n",
    "\n",
    "    # True labels for comparison\n",
    "    true_labels = label_tensor_test.numpy()\n",
    "\n",
    "    # Calculate precision-recall curve and corresponding thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(true_labels, test_probs)\n",
    "\n",
    "    # Calculate F-beta scores for each possible threshold\n",
    "    f_beta_scores = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "    f_beta_scores = np.nan_to_num(f_beta_scores)  # Handling NaNs\n",
    "\n",
    "    # Find the threshold that maximizes the F-beta score\n",
    "    optimal_idx = np.argmax(f_beta_scores)\n",
    "    best_threshold = thresholds[optimal_idx]\n",
    "\n",
    "    # Use the best threshold found\n",
    "    test_predictions = (test_probs > best_threshold).astype(int)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, test_predictions)\n",
    "    precision = precision_score(true_labels, test_predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, test_predictions)\n",
    "    f1 = f1_score(true_labels, test_predictions)\n",
    "    auc_roc = roc_auc_score(true_labels, test_probs)\n",
    "    auprc = average_precision_score(true_labels, test_probs)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Best Threshold: {best_threshold:.2f}\")\n",
    "    print(f\"{model_name} Model Performance on Test Set:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"AUC-ROC: {auc_roc:.2f}\")\n",
    "    print(f\"AUPRC: {auprc:.2f}\")\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save the confusion matrix\n",
    "    cm = confusion_matrix(true_labels, test_predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{directory}/{model_name}_confusion_matrix.png')\n",
    "    plt.close()  # Close the plot to avoid display\n",
    "\n",
    "    # Save performance metrics to a text file\n",
    "    metrics_filepath = f'{directory}/{model_name}_metrics.txt'\n",
    "    with open(metrics_filepath, 'w') as f:\n",
    "        f.write(f\"{model_name} Model Performance on Test Set:\\n\")\n",
    "        f.write(f\"Best Threshold: {best_threshold:.2f}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.2f}\\n\")\n",
    "        f.write(f\"Precision: {precision:.2f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.2f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1:.2f}\\n\")\n",
    "        f.write(f\"AUC-ROC: {auc_roc:.2f}\\n\")\n",
    "        f.write(f\"AUPRC: {auprc:.2f}\\n\")\n",
    "\n",
    "    print(f\"Performance metrics saved to: {metrics_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the percentage to load\n",
    "percentage = '1%'  # Change this to '5%', '10%', etc., as needed\n",
    "\n",
    "# Path to save tensors\n",
    "tensor_save_path = f'./data/tensors/{percentage}_subset'\n",
    "\n",
    "# Load tensors\n",
    "dynamic_train_tensor = torch.load(os.path.join(tensor_save_path, 'dynamic_train_tensor.pt'))\n",
    "static_train_tensor = torch.load(os.path.join(tensor_save_path, 'static_train_tensor.pt'))\n",
    "label_tensor_train = torch.load(os.path.join(tensor_save_path, 'label_train_tensor.pt'))\n",
    "train_tensor_repeated_static_features = torch.load(os.path.join(tensor_save_path, 'train_tensor_repeated_static_features.pt'))\n",
    "\n",
    "dynamic_test_tensor = torch.load(os.path.join(tensor_save_path, 'dynamic_test_tensor.pt'))\n",
    "static_test_tensor = torch.load(os.path.join(tensor_save_path, 'static_test_tensor.pt'))\n",
    "label_tensor_test = torch.load(os.path.join(tensor_save_path, 'label_test_tensor.pt'))\n",
    "test_tensor_repeated_static_features = torch.load(os.path.join(tensor_save_path, 'test_tensor_repeated_static_features.pt'))\n",
    "\n",
    "dynamic_val_tensor = torch.load(os.path.join(tensor_save_path, 'dynamic_val_tensor.pt'))\n",
    "static_val_tensor = torch.load(os.path.join(tensor_save_path, 'static_val_tensor.pt'))\n",
    "label_tensor_val = torch.load(os.path.join(tensor_save_path, 'label_val_tensor.pt'))\n",
    "val_tensor_repeated_static_features = torch.load(os.path.join(tensor_save_path, 'val_tensor_repeated_static_features.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(dynamic_train_tensor, static_train_tensor, label_tensor_train)\n",
    "test_dataset = TensorDataset(dynamic_test_tensor, static_test_tensor, label_tensor_test)\n",
    "val_dataset = TensorDataset(dynamic_val_tensor, static_val_tensor, label_tensor_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Hybrid LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual static features in train: 1486\n",
      "Actual static features in val: 1486\n",
      "Actual static features in test: 1486\n"
     ]
    }
   ],
   "source": [
    "# Check the actual number of features in the static data tensors\n",
    "#print(\"Expected num_static_features:\", num_static_features)\n",
    "print(\"Actual static features in train:\", static_train_tensor.shape[1])\n",
    "print(\"Actual static features in val:\", static_val_tensor.shape[1])\n",
    "print(\"Actual static features in test:\", static_test_tensor.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "class HybridLSTM(nn.Module):\n",
    "    def __init__(self, num_dynamic_features, num_static_features, hidden_dim, output_dim):\n",
    "        super(HybridLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=num_dynamic_features, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.static_dense = nn.Linear(num_static_features, hidden_dim)\n",
    "        self.final_dense = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, dynamic_input, static_input):\n",
    "        # Dynamic pathway\n",
    "        dynamic_output, (hidden, _) = self.lstm(dynamic_input)\n",
    "        # Take the last hidden state\n",
    "        dynamic_output = dynamic_output[:, -1, :]\n",
    "\n",
    "        # Static pathway\n",
    "        static_output = self.static_dense(static_input)\n",
    "\n",
    "        # Combine outputs\n",
    "        combined_output = torch.cat((dynamic_output, static_output), dim=1)\n",
    "        final_output = self.final_dense(combined_output)\n",
    "        return self.sigmoid(final_output)\n",
    "\n",
    "# Model instantiation\n",
    "num_dynamic_features = dynamic_train_tensor.shape[2]\n",
    "num_static_features = static_train_tensor.shape[1]  \n",
    "hidden_dim = 64\n",
    "output_dim = 1  # Binary classification\n",
    "\n",
    "model = HybridLSTM(num_dynamic_features, num_static_features, hidden_dim, output_dim)\n",
    "\n",
    "# Data preparation (using preprocessed tensors)\n",
    "train_dataset = TensorDataset(dynamic_train_tensor, static_train_tensor, label_tensor_train)\n",
    "val_dataset = TensorDataset(dynamic_val_tensor, static_val_tensor, label_tensor_val)\n",
    "test_dataset = TensorDataset(dynamic_test_tensor, static_test_tensor, label_tensor_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Forward pass\n",
    "for dynamic_data, static_data, labels in train_loader:\n",
    "    outputs = model(dynamic_data, static_data)\n",
    "    print(outputs.shape)  # Output shape check\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 0.4210826903581619, Validation Loss: 0.30444792211055755\n",
      "Epoch 2/100, Training Loss: 0.22402601192394891, Validation Loss: 0.2855829581618309\n",
      "Epoch 3/100, Training Loss: 0.18894144839474133, Validation Loss: 0.2795951724052429\n",
      "Epoch 4/100, Training Loss: 0.13064431824854442, Validation Loss: 0.24796746671199799\n",
      "Epoch 5/100, Training Loss: 0.08742591162167844, Validation Loss: 0.2351682037115097\n",
      "Epoch 6/100, Training Loss: 0.05231369827829656, Validation Loss: 0.2385803282260895\n",
      "Epoch 7/100, Training Loss: 0.02856482718405979, Validation Loss: 0.24145342856645585\n",
      "Epoch 8/100, Training Loss: 0.015772479497605844, Validation Loss: 0.23781427145004272\n",
      "Epoch 00009: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 9/100, Training Loss: 0.010186099292089542, Validation Loss: 0.24697076082229613\n",
      "Epoch 10/100, Training Loss: 0.007532932529492038, Validation Loss: 0.24879610538482666\n",
      "Epoch 11/100, Training Loss: 0.006516582238310505, Validation Loss: 0.2521039456129074\n",
      "Epoch 12/100, Training Loss: 0.005684338255031477, Validation Loss: 0.2545214667916298\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 13/100, Training Loss: 0.005045970985000687, Validation Loss: 0.25755603015422823\n",
      "Epoch 14/100, Training Loss: 0.004610135347493703, Validation Loss: 0.25848539620637895\n",
      "Epoch 15/100, Training Loss: 0.0043766106744962075, Validation Loss: 0.26024374067783357\n",
      "Early stopping initiated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HybridLSTM(\n",
       "  (lstm): LSTM(835, 64, batch_first=True)\n",
       "  (static_dense): Linear(in_features=1486, out_features=64, bias=True)\n",
       "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model definition and training loop\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 10\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for dynamic_input, static_input, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(dynamic_input, static_input).squeeze()\n",
    "        outputs = outputs.view(-1)  # Ensure output and labels have the same shape\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Implement gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for dynamic_input, static_input, labels in val_loader:\n",
    "            outputs = model(dynamic_input, static_input).squeeze()\n",
    "            outputs = outputs.view(-1)  # Flatten the output for consistency\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {total_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './saved_models/Hybrid_LSTM/state_dict/best_hybrid_lstm_model.pth')  # Save the best model\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == early_stopping_patience:\n",
    "            print(\"Early stopping initiated.\")\n",
    "            break\n",
    "\n",
    "# Optionally, load the best model for further use or evaluation\n",
    "model.load_state_dict(torch.load('./saved_models/Hybrid_LSTM/state_dict/best_hybrid_lstm_model.pth'))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.17177575826644897\n",
      "Test Accuracy: 0.9154929518699646\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load('./saved_models/Hybrid_LSTM/state_dict/best_hybrid_lstm_model.pth'))\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(dynamic_test_tensor, static_test_tensor).squeeze()\n",
    "    test_loss = criterion(test_outputs, label_tensor_test)\n",
    "    test_predictions = (test_outputs > 0.5).int()\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "print(f\"Test Accuracy: {(test_predictions == label_tensor_test.int()).float().mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path\n",
    "directory_path = f'./saved_models/Hybrid_LSTM/trained_on_{percentage}'\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "\n",
    "# Save model and optimizer state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, os.path.join(directory_path, 'best_hybrid_LSTM_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.14\n",
      "Hybrid_LSTM Model Performance on Test Set:\n",
      "Accuracy: 0.89\n",
      "Precision: 0.42\n",
      "Recall: 0.83\n",
      "F1 Score: 0.56\n",
      "AUC-ROC: 0.96\n",
      "AUPRC: 0.58\n",
      "Performance metrics saved to: ./saved_models/Hybrid_LSTM/trained_on_1%//Hybrid_LSTM_metrics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soere\\AppData\\Local\\Temp\\ipykernel_33124\\2004008501.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta_scores = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "evaluate_hybrid_lstm_model(model, dynamic_test_tensor, static_test_tensor, label_tensor_test, f'./saved_models/Hybrid_LSTM/trained_on_{percentage}/', 'Hybrid_LSTM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
